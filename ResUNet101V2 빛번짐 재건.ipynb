{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d4397bf",
   "metadata": {},
   "source": [
    "# 학습 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51930408",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 32\n",
    "train_image_size = 256\n",
    "train_stride = 128\n",
    "\n",
    "train_epoch = 5\n",
    "train_learning_rate = 1e-4\n",
    "\n",
    "train_alpha = 150    # PSNR\n",
    "train_beta = 30      # SSIM\n",
    "train_lambda = 60   # Reonconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8737b377",
   "metadata": {},
   "source": [
    "# 학습 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "973a5702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def train_map_func(inp_path, targ_path):\n",
    "    inp = np.load(inp_path)\n",
    "    inp = inp.astype(np.float32) / 255\n",
    "    targ = np.load(targ_path)\n",
    "    targ = targ.astype(np.float32) / 255\n",
    "    inp, targ = augmentation(inp, targ)\n",
    "    return inp, targ\n",
    "\n",
    "\n",
    "def val_map_func(inp_path, targ_path):\n",
    "    inp = np.load(inp_path)\n",
    "    inp = inp.astype(np.float32) / 255\n",
    "    targ = np.load(targ_path)\n",
    "    targ = targ.astype(np.float32) / 255\n",
    "    return inp, targ\n",
    "\n",
    "\n",
    "def augmentation(inp, targ):\n",
    "    inp, targ = random_rot(inp, targ)\n",
    "    inp, targ = random_flip(inp, targ)\n",
    "    return inp, targ\n",
    "\n",
    "\n",
    "def random_rot(inp, targ):\n",
    "    k = np.random.randint(4)\n",
    "    inp = np.rot90(inp, k)\n",
    "    targ = np.rot90(targ, k)\n",
    "    return inp, targ\n",
    "\n",
    "\n",
    "def random_flip(inp, targ):\n",
    "    f = np.random.randint(2)\n",
    "    if f == 0:\n",
    "        inp = np.fliplr(inp)\n",
    "        targ = np.fliplr(targ)\n",
    "    return inp, targ\n",
    "\n",
    "\n",
    "def read_raw_dataset_list(path):\n",
    "    train_csv = pd.read_csv(os.path.join(path, 'train.csv'))\n",
    "    test_csv = pd.read_csv(os.path.join(path, 'test.csv'))\n",
    "    \n",
    "    train_input_all_files = os.path.join(path, 'train') + os.path.sep + train_csv['input_img']\n",
    "    train_label_all_files = os.path.join(path, 'label') + os.path.sep + train_csv['label_img']\n",
    "    \n",
    "    test_all_files = os.path.join(path, 'test') + os.path.sep + test_csv['input_img']\n",
    "    submission_all_files = os.path.join(path, 'test') + os.path.sep + test_csv['submission_name']\n",
    "    \n",
    "    train_input_files = train_input_all_files[60:].to_numpy()\n",
    "    train_label_files = train_label_all_files[60:].to_numpy()\n",
    "    val_input_files = train_input_all_files[:60].to_numpy()\n",
    "    val_label_files = train_label_all_files[:60].to_numpy()\n",
    "    return train_input_files, train_label_files, val_input_files, val_label_files, test_all_files, submission_all_files\n",
    "\n",
    "\n",
    "def create_dataset_generator(path, batch_size, image_size):\n",
    "    train_input_files = glob(os.path.join(path, f'train_', f'{image_size}', '*.npy'))\n",
    "    train_label_files = glob(os.path.join(path, f'label_', f'{image_size}', '*.npy'))\n",
    "    val_input_files = glob(os.path.join(path, f'val_train_', f'{image_size}', '*.npy'))\n",
    "    val_label_files = glob(os.path.join(path, f'val_label_', f'{image_size}', '*.npy'))\n",
    "    train_input_files, train_label_files = shuffle(train_input_files, train_label_files, random_state=42)\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_input_files, train_label_files))\n",
    "    train_dataset = train_dataset.map(lambda i1, i2: tf.numpy_function(train_map_func, [i1, i2], [tf.float32, tf.float32]),\n",
    "                                      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((val_input_files, val_label_files))\n",
    "    val_dataset = val_dataset.map(lambda i1, i2: tf.numpy_function(val_map_func, [i1, i2], [tf.float32, tf.float32]),\n",
    "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    val_dataset = val_dataset.batch(batch_size)\n",
    "    val_dataset = val_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7008d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator, validate_generator = create_dataset_generator('./Dacon/LG', train_batch_size, train_image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf93841",
   "metadata": {},
   "source": [
    "# ResUNet101V2 신경망 모델\n",
    "영상 재건을 위한 ResUNet101V2 모델을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ad0381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
    "    x = tf.keras.layers.Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    if activation == True:\n",
    "        x = tf.keras.layers.LeakyReLU(alpha=0.1)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def residual_block(blockInput, num_filters=16):\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.1)(blockInput)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    blockInput = tf.keras.layers.BatchNormalization()(blockInput)\n",
    "    x = convolution_block(x, num_filters, (3,3) )\n",
    "    x = convolution_block(x, num_filters, (3,3), activation=False)\n",
    "    x = tf.keras.layers.Add()([x, blockInput])\n",
    "    return x\n",
    "\n",
    "\n",
    "def ResUNet101V2(image_size, weights='imagenet', dropout_rate=0.1, start_neurons=16):\n",
    "    input_shape=(image_size, image_size, 3)\n",
    "    backbone = tf.keras.applications.ResNet101V2(weights=weights, include_top=False, input_shape=input_shape)\n",
    "    input_layer = backbone.input\n",
    "\n",
    "    conv4 = backbone.layers[122].output\n",
    "    conv4 = tf.keras.layers.LeakyReLU(alpha=0.1)(conv4)\n",
    "    pool4 = tf.keras.layers.MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = tf.keras.layers.Dropout(dropout_rate)(pool4)\n",
    "\n",
    "    convm = tf.keras.layers.Conv2D(start_neurons * 32, (3, 3), activation=None, padding='same')(pool4)\n",
    "    convm = residual_block(convm, start_neurons * 32)\n",
    "    convm = residual_block(convm, start_neurons * 32)\n",
    "    convm = tf.keras.layers.LeakyReLU(alpha=0.1)(convm)\n",
    "\n",
    "    deconv4 = tf.keras.layers.Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding='same')(convm)\n",
    "    uconv4 = tf.keras.layers.concatenate([deconv4, conv4])\n",
    "    uconv4 = tf.keras.layers.Dropout(dropout_rate)(uconv4)\n",
    "\n",
    "    uconv4 = tf.keras.layers.Conv2D(start_neurons * 16, (3, 3), activation=None, padding='same')(uconv4)\n",
    "    uconv4 = residual_block(uconv4, start_neurons * 16)\n",
    "    uconv4 = residual_block(uconv4, start_neurons * 16)\n",
    "    uconv4 = tf.keras.layers.LeakyReLU(alpha=0.1)(uconv4)\n",
    "\n",
    "    deconv3 = tf.keras.layers.Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding='same')(uconv4)\n",
    "    conv3 = backbone.layers[76].output\n",
    "    uconv3 = tf.keras.layers.concatenate([deconv3, conv3])\n",
    "    uconv3 = tf.keras.layers.Dropout(dropout_rate)(uconv3)\n",
    "\n",
    "    uconv3 = tf.keras.layers.Conv2D(start_neurons * 8, (3, 3), activation=None, padding='same')(uconv3)\n",
    "    uconv3 = residual_block(uconv3, start_neurons * 8)\n",
    "    uconv3 = residual_block(uconv3, start_neurons * 8)\n",
    "    uconv3 = tf.keras.layers.LeakyReLU(alpha=0.1)(uconv3)\n",
    "\n",
    "    deconv2 = tf.keras.layers.Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding='same')(uconv3)\n",
    "    conv2 = backbone.layers[30].output\n",
    "    uconv2 = tf.keras.layers.concatenate([deconv2, conv2])\n",
    "\n",
    "    uconv2 = tf.keras.layers.Dropout(0.1)(uconv2)\n",
    "    uconv2 = tf.keras.layers.Conv2D(start_neurons * 4, (3, 3), activation=None, padding='same')(uconv2)\n",
    "    uconv2 = residual_block(uconv2, start_neurons * 4)\n",
    "    uconv2 = residual_block(uconv2, start_neurons * 4)\n",
    "    uconv2 = tf.keras.layers.LeakyReLU(alpha=0.1)(uconv2)\n",
    "\n",
    "    deconv1 = tf.keras.layers.Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding='same')(uconv2)\n",
    "    conv1 = backbone.layers[2].output\n",
    "    uconv1 = tf.keras.layers.concatenate([deconv1, conv1])\n",
    "\n",
    "    uconv1 = tf.keras.layers.Dropout(0.1)(uconv1)\n",
    "    uconv1 = tf.keras.layers.Conv2D(start_neurons * 2, (3, 3), activation=None, padding='same')(uconv1)\n",
    "    uconv1 = residual_block(uconv1, start_neurons * 2)\n",
    "    uconv1 = residual_block(uconv1, start_neurons * 2)\n",
    "    uconv1 = tf.keras.layers.LeakyReLU(alpha=0.1)(uconv1)\n",
    "\n",
    "    uconv0 = tf.keras.layers.Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding='same')(uconv1)\n",
    "    uconv0 = tf.keras.layers.Dropout(0.1)(uconv0)\n",
    "    uconv0 = tf.keras.layers.Conv2D(start_neurons * 1, (3, 3), activation=None, padding='same')(uconv0)\n",
    "    uconv0 = residual_block(uconv0, start_neurons * 1)\n",
    "    uconv0 = residual_block(uconv0, start_neurons * 1)\n",
    "    uconv0 = tf.keras.layers.LeakyReLU(alpha=0.1)(uconv0)\n",
    "\n",
    "    uconv0 = tf.keras.layers.Dropout(dropout_rate / 2)(uconv0)\n",
    "    output_layer = tf.keras.layers.Conv2D(3, (1, 1), padding='same', activation='sigmoid')(uconv0)\n",
    "\n",
    "    model = tf.keras.models.Model(input_layer, output_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22bd252",
   "metadata": {},
   "source": [
    "# 손실 함수 정의\n",
    "학습에 사용할 손실 함수를 정의합니다.</br>\n",
    "Loss = αL2(PSNR 지표) + βSSIM(영상 유사도 지표) + λL1(Reconstruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81a8adc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr_loss(y_true, y_pred):\n",
    "    return tf.keras.losses.mean_squared_error(y_true, y_pred)\n",
    "\n",
    "def ssim_loss(y_true, y_pred):\n",
    "    return 1. - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))\n",
    "\n",
    "def recon_loss(y_true, y_pred):\n",
    "    return tf.keras.losses.mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "def create_psnr_ssim_recon_combined_loss(alpha_, beta_, lambda_):\n",
    "    def psnr_ssim_recon_combined_loss(y_true, y_pred):\n",
    "        return (alpha_ * psnr_loss(y_true, y_pred)) + (beta_ * ssim_loss(y_true, y_pred)) + (lambda_ * recon_loss(y_true, y_pred))\n",
    "    return psnr_ssim_recon_combined_loss\n",
    "\n",
    "combined_loss = create_psnr_ssim_recon_combined_loss(train_alpha, train_beta, train_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7a0a00",
   "metadata": {},
   "source": [
    "# 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b217afda",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=train_learning_rate)\n",
    "model = ResUNet101V2(train_image_size)\n",
    "model.compile(optimizer=optimizer, loss=combined_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c8a1ce",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ce43187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4867/4867 [==============================] - 1487s 304ms/step - loss: 26.3295 - val_loss: 4.0925\n",
      "Epoch 2/5\n",
      "4867/4867 [==============================] - 1476s 303ms/step - loss: 6.0675 - val_loss: 4.3698\n",
      "Epoch 3/5\n",
      "4867/4867 [==============================] - 1475s 303ms/step - loss: 4.7038 - val_loss: 4.2174\n",
      "Epoch 4/5\n",
      "4867/4867 [==============================] - 1476s 303ms/step - loss: 4.2334 - val_loss: 3.8190\n",
      "Epoch 5/5\n",
      "4867/4867 [==============================] - 1475s 303ms/step - loss: 3.9789 - val_loss: 3.8417\n"
     ]
    }
   ],
   "source": [
    "model_name = f'ResUNet101V2_RGB_PSNR+SSIM+Recon_{train_image_size}_alpha_{train_alpha}_beta_{train_beta}_lambda_{train_lambda}'\n",
    "\n",
    "train_history = model.fit(train_generator, epochs=train_epoch, validation_data=validate_generator, callbacks=[\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=f'{model_name}_epoch_{train_epoch}_best.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=f'{model_name}_epoch_{train_epoch}_last.h5',\n",
    "        save_freq=512\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598488ae",
   "metadata": {},
   "source": [
    "# 영상 품질 평가 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a78992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def rmse_score(true, pred):\n",
    "    score = math.sqrt(np.mean((true - pred) ** 2))\n",
    "    return score\n",
    "\n",
    "def psnr_score(true, pred, pixel_max):\n",
    "    score = 20 * np.log10(pixel_max / rmse_score(true,pred))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95e08c2",
   "metadata": {},
   "source": [
    "# 추론 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c83336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def predict(model, img_paths, image_size, stride, batch_size):\n",
    "    results = []\n",
    "    for i, img_path in enumerate(img_paths):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = img.astype(np.float32) / 255\n",
    "        crop = []\n",
    "        position = []\n",
    "        batch_count = 0\n",
    "        \n",
    "        result_img = np.zeros_like(img)\n",
    "        voting_mask = np.zeros_like(img)\n",
    "        for top in tqdm(range(0, img.shape[0], stride), desc=f'Predicting ({i + 1}/{len(img_paths)})'):\n",
    "            for left in range(0, img.shape[1], stride):\n",
    "                piece = np.zeros([image_size, image_size, 3], np.float32)\n",
    "                temp = img[top:top + image_size, left:left + image_size, :]\n",
    "                piece[:temp.shape[0], :temp.shape[1], :] = temp\n",
    "                crop.append(piece)\n",
    "                position.append([top, left])\n",
    "                batch_count += 1\n",
    "                if batch_count == batch_size:\n",
    "                    crop = np.array(crop)\n",
    "                    pred = model(crop) * 255\n",
    "                    crop = []\n",
    "                    batch_count=0\n",
    "                    for num, (t, l) in enumerate(position):\n",
    "                        piece = pred[num]\n",
    "                        h, w, c = result_img[t:t + image_size, l:l + image_size,:].shape\n",
    "                        result_img[t:t + image_size, l:l + image_size,:] += piece[:h, :w]\n",
    "                        voting_mask[t:t + image_size, l:l + image_size, :] += 1\n",
    "                    position = []\n",
    "                    \n",
    "        result_img = result_img / voting_mask\n",
    "        result_img = result_img.astype(np.uint8)\n",
    "        results.append(result_img)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93a8a83",
   "metadata": {},
   "source": [
    "# 빚번짐 제거 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b079bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 모델 로딩\n",
    "fronzen_model_filename = 'ResUNet101V2_RGB_PSNR+SSIM+Recon_256_alpha_10_beta_5_lambda_20_epoch_5_best.h5'\n",
    "model = tf.keras.models.load_model(fronzen_model_filename, custom_objects={combined_loss.__name__: combined_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703024c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_files, train_label_files, val_input_files, val_label_files, _, _ = read_raw_dataset_list('./Dacon/LG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cc75ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_image_size = 256\n",
    "pred_stride = 32\n",
    "pred_batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dfea23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_images = [cv2.imread(fn, cv2.IMREAD_COLOR) for fn in val_input_files[:1]]\n",
    "label_images = [cv2.imread(fn, cv2.IMREAD_COLOR) for fn in val_label_files[:1]]\n",
    "predicted_images = predict(model, val_input_files[:1], pred_image_size, pred_stride, pred_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3fbff8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(input_images[0])\n",
    "plt.title('Input', fontsize=10)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(label_images[0])\n",
    "plt.title('Label', fontsize=10)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(predicted_images[0])\n",
    "plt.title('Predicted', fontsize=10)\n",
    "\n",
    "print(f'PSNR: {psnr_score(label_images[0], predicted_images[0], 255)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec76a2c",
   "metadata": {},
   "source": [
    "# 결과 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e43baf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def make_submission(result):\n",
    "    root_path = 'submission'\n",
    "    os.makedirs(root_path, exist_ok=True)\n",
    "    with zipfile.ZipFile(\"submission.zip\", 'w') as submit:\n",
    "        for i, img in tqdm(enumerate(result), total=len(result), desc='Compressing'):\n",
    "            arcname = f'test_{20000 + i}.png'\n",
    "            absname = os.path.join(root_path, arcname)\n",
    "            cv2.imwrite(absname, img)\n",
    "            submit.write(absname, arcname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b5f1b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "_, _, _, _, test_all_files, _ = read_raw_dataset_list('./Dacon/LG')\n",
    "test_input_images = [cv2.imread(fn, cv2.IMREAD_COLOR) for fn in test_all_files]\n",
    "predicted_images = predict(model, test_all_files, pred_image_size, pred_stride, pred_batch_size)\n",
    "make_submission(predicted_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545710c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(predicted_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
